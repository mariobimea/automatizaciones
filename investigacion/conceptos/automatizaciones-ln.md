# Automatizaciones con CÃ³digo: Lo que REALMENTE Necesitas

Vamos a ir al grano. Ya entiendes QUÃ‰ es una automatizaciÃ³n. Ahora vamos a ver QUÃ‰ NECESITAS INSTALAR Y CONFIGURAR para que funcione.

---

## LA PREGUNTA CLAVE: Â¿QuÃ© necesito para hacer automatizaciones con cÃ³digo?

### Respuesta corta:
1. **Python** (el lenguaje)
2. **Celery** (para ejecutar trabajos en segundo plano)
3. **Redis** (para la cola de trabajos)
4. **PostgreSQL** (para guardar datos)
5. **FastAPI** (para la API)
6. **React** (opcional, para la UI)

---

## DESGLOSE PIEZA POR PIEZA

### 1. CELERY - El motor que ejecuta trabajos

**Â¿QuÃ© es Celery?**
Celery es una librerÃ­a de Python que te permite ejecutar cÃ³digo "en segundo plano" sin bloquear tu aplicaciÃ³n.

**Â¿Por quÃ© lo necesitas?**
Porque si procesas una factura directamente en tu API, el usuario tiene que esperar 10-20 segundos hasta que termine. Con Celery:
- Recibes la peticiÃ³n
- La encolas (0.1 segundos)
- Respondes "OK, lo estoy procesando"
- Celery lo procesa en segundo plano

**InstalaciÃ³n:**
```bash
pip install celery
```

**ConfiguraciÃ³n bÃ¡sica:**
```python
# celery_config.py
from celery import Celery

# Crear la app de Celery
app = Celery(
    'mi_sistema',
    broker='redis://localhost:6379/0',    # DÃ³nde estÃ¡ la cola
    backend='redis://localhost:6379/0'     # DÃ³nde guarda resultados
)

# ConfiguraciÃ³n
app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Europe/Madrid',
    enable_utc=True,
)
```

**Definir un trabajo (task):**
```python
# tasks/procesar_factura.py
from celery_config import app

@app.task
def procesar_factura(email_id):
    """
    Este es un "trabajo" que Celery puede ejecutar en segundo plano
    """
    print(f"Procesando factura del email {email_id}")

    # AquÃ­ va tu lÃ³gica
    # - Descargar email
    # - Extraer PDF
    # - Validar datos
    # - Guardar en DB

    return {"status": "ok", "factura_id": 123}
```

**Ejecutar el trabajo:**
```python
# Desde tu API o cualquier cÃ³digo Python
from tasks.procesar_factura import procesar_factura

# OpciÃ³n 1: Ejecutar AHORA (bloqueante)
resultado = procesar_factura(email_id="email_123")

# OpciÃ³n 2: Encolar y ejecutar cuando haya un worker disponible (recomendado)
resultado = procesar_factura.delay("email_123")
# â†’ Esto devuelve inmediatamente, no espera

# OpciÃ³n 3: Ejecutar despuÃ©s de 60 segundos
resultado = procesar_factura.apply_async(
    args=["email_123"],
    countdown=60
)
```

**Arrancar los workers de Celery:**
```bash
# En una terminal separada
celery -A celery_config worker --loglevel=info

# Esto arranca un "worker" que estÃ¡ esperando trabajos en la cola
# Puedes arrancar mÃºltiples workers para procesar mÃ¡s trabajos en paralelo
```

**Â¿QuÃ© pasa cuando arrancas un worker?**
```
[2024-10-17 10:30:00] Celery worker starting...
[2024-10-17 10:30:01] Connected to redis://localhost:6379/0
[2024-10-17 10:30:01] Ready to receive tasks

# Cuando llegas un trabajo
[2024-10-17 10:30:15] Received task: procesar_factura[abc-123-def]
[2024-10-17 10:30:15] Procesando factura del email email_123
[2024-10-17 10:30:25] Task procesar_factura[abc-123-def] succeeded: {"status": "ok"}
```

---

### 2. REDIS - La cola de trabajos

**Â¿QuÃ© es Redis?**
Una base de datos en memoria ultra-rÃ¡pida. Celery la usa para:
- Guardar la cola de trabajos pendientes
- Guardar los resultados de trabajos completados
- Coordinar mÃºltiples workers

**Â¿Por quÃ© lo necesitas?**
Sin Redis, Celery no puede funcionar. Es donde vive la "cola" de trabajos.

**InstalaciÃ³n (macOS):**
```bash
brew install redis
```

**InstalaciÃ³n (Ubuntu/Debian):**
```bash
sudo apt-get install redis-server
```

**InstalaciÃ³n (Docker):**
```bash
docker run -d -p 6379:6379 redis:alpine
```

**Arrancar Redis:**
```bash
# macOS/Linux
redis-server

# O en segundo plano
redis-server --daemonize yes
```

**Comprobar que funciona:**
```bash
redis-cli ping
# Respuesta: PONG
```

**Â¿QuÃ© hace Redis internamente?**
```
REDIS (corriendo en localhost:6379)
====================================

Cola de trabajos pendientes:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ celery:                             â”‚
â”‚   - procesar_factura (email_123)    â”‚
â”‚   - procesar_factura (email_456)    â”‚
â”‚   - procesar_factura (email_789)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resultados de trabajos completados:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ celery-task-meta-abc-123-def:       â”‚
â”‚   {"status": "ok", "factura_id": 1} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Workers activos:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ celery@mario-macbook: IDLE          â”‚
â”‚ celery@server-2: BUSY               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ver quÃ© hay en la cola (comando Ãºtil):**
```bash
# Ver cuÃ¡ntos trabajos pendientes
redis-cli llen celery

# Ver trabajos activos
celery -A celery_config inspect active

# Ver workers conectados
celery -A celery_config inspect stats
```

---

### 3. APSCHEDULER - El programador de tareas (cron)

**Â¿QuÃ© es APScheduler?**
Una librerÃ­a que ejecuta cÃ³digo en momentos especÃ­ficos:
- "Cada 5 minutos"
- "Todos los dÃ­as a las 9:00"
- "Cada lunes a las 8:00"

Es como el `cron` de Linux pero en Python.

**Â¿Por quÃ© lo necesitas?**
Para los **triggers**: "Revisa emails nuevos cada 5 minutos"

**InstalaciÃ³n:**
```bash
pip install apscheduler
```

**ConfiguraciÃ³n:**
```python
# scheduler.py
from apscheduler.schedulers.background import BackgroundScheduler
from tasks.procesar_factura import procesar_factura

# Crear el scheduler
scheduler = BackgroundScheduler()

def revisar_emails():
    """
    Esta funciÃ³n se ejecuta cada 5 minutos
    """
    print("Revisando emails nuevos...")

    # AquÃ­ irÃ­as a Gmail y buscarÃ­as emails nuevos
    # Por cada email nuevo, encolas un worker
    emails_nuevos = ["email_123", "email_456"]

    for email_id in emails_nuevos:
        procesar_factura.delay(email_id)
        print(f"Encolado worker para {email_id}")

# Programar: ejecutar cada 5 minutos
scheduler.add_job(
    revisar_emails,
    'interval',
    minutes=5,
    id='revisar_emails'
)

# Iniciar el scheduler
scheduler.start()
print("Scheduler iniciado")

# Mantener el script corriendo
import time
try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    scheduler.shutdown()
```

**Arrancar el scheduler:**
```bash
python scheduler.py

# Output:
Scheduler iniciado
Revisando emails nuevos...
Encolado worker para email_123
Encolado worker para email_456
# (espera 5 minutos)
Revisando emails nuevos...
Encolado worker para email_789
```

**Opciones de programaciÃ³n:**

```python
# Cada X minutos
scheduler.add_job(mi_funcion, 'interval', minutes=5)

# Cada X horas
scheduler.add_job(mi_funcion, 'interval', hours=2)

# Cada dÃ­a a las 9:00
scheduler.add_job(mi_funcion, 'cron', hour=9, minute=0)

# Cada lunes a las 8:30
scheduler.add_job(mi_funcion, 'cron', day_of_week='mon', hour=8, minute=30)

# De lunes a viernes a las 9:00
scheduler.add_job(mi_funcion, 'cron', day_of_week='mon-fri', hour=9, minute=0)

# Cada 30 segundos
scheduler.add_job(mi_funcion, 'interval', seconds=30)
```

---

### 4. POSTGRESQL - La base de datos

**Â¿QuÃ© es PostgreSQL?**
Una base de datos relacional donde guardas todos tus datos:
- Facturas procesadas
- Proveedores autorizados
- Historial de ejecuciones
- Errores

**Â¿Por quÃ© lo necesitas?**
Porque necesitas persistir datos. Redis solo guarda cosas temporalmente.

**InstalaciÃ³n (macOS):**
```bash
brew install postgresql
brew services start postgresql
```

**InstalaciÃ³n (Ubuntu/Debian):**
```bash
sudo apt-get install postgresql postgresql-contrib
sudo systemctl start postgresql
```

**InstalaciÃ³n (Docker):**
```bash
docker run -d \
  --name postgres \
  -e POSTGRES_PASSWORD=mipassword \
  -e POSTGRES_DB=facturas \
  -p 5432:5432 \
  postgres:15-alpine
```

**Crear la base de datos:**
```bash
# Conectar a PostgreSQL
psql -U postgres

# Crear base de datos
CREATE DATABASE facturas;

# Conectar a la base de datos
\c facturas

# Crear tabla de facturas
CREATE TABLE facturas (
    id SERIAL PRIMARY KEY,
    nif VARCHAR(9) NOT NULL,
    importe DECIMAL(10,2) NOT NULL,
    fecha DATE NOT NULL,
    email_id VARCHAR(255) NOT NULL,
    estado VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

# Crear tabla de proveedores
CREATE TABLE proveedores (
    id SERIAL PRIMARY KEY,
    nif VARCHAR(9) UNIQUE NOT NULL,
    nombre VARCHAR(255) NOT NULL,
    activo BOOLEAN DEFAULT true
);

# Salir
\q
```

**Conectar desde Python:**
```bash
pip install psycopg2-binary
```

```python
import psycopg2

# Conectar
conn = psycopg2.connect(
    dbname="facturas",
    user="postgres",
    password="mipassword",
    host="localhost",
    port="5432"
)

# Crear cursor
cur = conn.cursor()

# Insertar factura
cur.execute("""
    INSERT INTO facturas (nif, importe, fecha, email_id, estado)
    VALUES (%s, %s, %s, %s, %s)
    RETURNING id
""", ("B12345678", 1500.00, "2024-10-17", "email_123", "PENDIENTE"))

factura_id = cur.fetchone()[0]
print(f"Factura guardada con ID: {factura_id}")

# Commit
conn.commit()

# Cerrar
cur.close()
conn.close()
```

**Comandos Ãºtiles de PostgreSQL:**
```bash
# Ver todas las bases de datos
psql -U postgres -c "\l"

# Ver todas las tablas
psql -U postgres -d facturas -c "\dt"

# Ver datos de una tabla
psql -U postgres -d facturas -c "SELECT * FROM facturas LIMIT 10"

# Backup
pg_dump -U postgres facturas > backup.sql

# Restore
psql -U postgres facturas < backup.sql
```

---

### 5. FASTAPI - La API REST

**Â¿QuÃ© es FastAPI?**
Un framework para crear APIs REST en Python. Es como Express.js pero en Python.

**Â¿Por quÃ© lo necesitas?**
Para que tu frontend (React) pueda:
- Ver el dashboard
- Listar facturas
- Ver errores
- Ejecutar workers manualmente

**InstalaciÃ³n:**
```bash
pip install fastapi uvicorn
```

**Crear API bÃ¡sica:**
```python
# api/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import psycopg2

app = FastAPI()

# Permitir CORS (para que React pueda llamar a la API)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

def get_db():
    return psycopg2.connect(
        dbname="facturas",
        user="postgres",
        password="mipassword",
        host="localhost"
    )

@app.get("/")
def root():
    return {"message": "API de Facturas"}

@app.get("/api/facturas")
def get_facturas():
    conn = get_db()
    cur = conn.cursor()

    cur.execute("""
        SELECT id, nif, importe, fecha, estado
        FROM facturas
        ORDER BY created_at DESC
        LIMIT 50
    """)

    facturas = []
    for row in cur.fetchall():
        facturas.append({
            "id": row[0],
            "nif": row[1],
            "importe": float(row[2]),
            "fecha": str(row[3]),
            "estado": row[4]
        })

    conn.close()
    return {"facturas": facturas}

@app.post("/api/procesar-factura/{email_id}")
def procesar_factura_manual(email_id: str):
    from tasks.procesar_factura import procesar_factura

    # Encolar el trabajo
    task = procesar_factura.delay(email_id)

    return {
        "status": "enqueued",
        "task_id": task.id
    }
```

**Arrancar la API:**
```bash
uvicorn api.main:app --reload --port 8000

# Output:
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

**Probar la API:**
```bash
# Ver facturas
curl http://localhost:8000/api/facturas

# Procesar factura manualmente
curl -X POST http://localhost:8000/api/procesar-factura/email_123
```

---

### 6. REACT (Opcional) - La interfaz web

**Â¿QuÃ© es React?**
Una librerÃ­a de JavaScript para crear interfaces de usuario.

**Â¿Por quÃ© lo necesitas?**
Para tener un panel visual como n8n donde veas:
- Dashboard con mÃ©tricas
- Lista de facturas
- Historial de ejecuciones
- Errores

**InstalaciÃ³n:**
```bash
npx create-react-app frontend
cd frontend
npm start
```

**Conectar con tu API:**
```typescript
// frontend/src/App.tsx
import React, { useEffect, useState } from 'react';

function App() {
  const [facturas, setFacturas] = useState([]);

  useEffect(() => {
    // Llamar a la API
    fetch('http://localhost:8000/api/facturas')
      .then(res => res.json())
      .then(data => setFacturas(data.facturas));
  }, []);

  return (
    <div>
      <h1>Facturas</h1>
      <table>
        <thead>
          <tr>
            <th>ID</th>
            <th>NIF</th>
            <th>Importe</th>
            <th>Estado</th>
          </tr>
        </thead>
        <tbody>
          {facturas.map((f: any) => (
            <tr key={f.id}>
              <td>{f.id}</td>
              <td>{f.nif}</td>
              <td>{f.importe} â‚¬</td>
              <td>{f.estado}</td>
            </tr>
          ))}
        </tbody>
      </table>
    </div>
  );
}

export default App;
```

---

## RESUMEN: Â¿QUÃ‰ NECESITO INSTALAR?

### Instalaciones necesarias:

```bash
# 1. Redis (la cola)
brew install redis
redis-server

# 2. PostgreSQL (la base de datos)
brew install postgresql
brew services start postgresql

# 3. LibrerÃ­as Python
pip install celery redis psycopg2-binary apscheduler fastapi uvicorn

# 4. (Opcional) React para UI
npx create-react-app frontend
```

### Arrancar todo:

```bash
# Terminal 1: Redis
redis-server

# Terminal 2: Worker de Celery
celery -A celery_config worker --loglevel=info

# Terminal 3: Scheduler (triggers)
python scheduler.py

# Terminal 4: API
uvicorn api.main:app --reload

# Terminal 5 (opcional): Frontend React
cd frontend && npm start
```

---

## ESTRUCTURA DE ARCHIVOS FINAL

```
mi-sistema-facturas/
â”œâ”€â”€ celery_config.py          # ConfiguraciÃ³n de Celery
â”œâ”€â”€ scheduler.py               # Triggers (APScheduler)
â”œâ”€â”€ tasks/
â”‚   â””â”€â”€ procesar_factura.py    # Workers (lÃ³gica de negocio)
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                # FastAPI (endpoints)
â”œâ”€â”€ database/
â”‚   â””â”€â”€ schema.sql             # Estructura de PostgreSQL
â”œâ”€â”€ frontend/                  # React (opcional)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â””â”€â”€ requirements.txt           # Dependencias Python
```

**requirements.txt:**
```
celery==5.3.4
redis==5.0.1
psycopg2-binary==2.9.9
apscheduler==3.10.4
fastapi==0.104.1
uvicorn==0.24.0
```

---

## LA PREGUNTA DEL MILLÃ“N: Â¿Es complicado?

**Respuesta honesta**: La PRIMERA vez que lo montas, sÃ­, es un poco lioso porque tienes que:
1. Instalar Redis
2. Instalar PostgreSQL
3. Configurar Celery
4. Arrancar todo en terminales separadas

**PERO**: Una vez que lo tienes montado (1-2 horas), aÃ±adir NUEVOS workers es trivial:

```python
# Nuevo worker: enviar email de bienvenida
@app.task
def enviar_email_bienvenida(user_id):
    user = get_user_from_db(user_id)
    send_email(user.email, "Bienvenido!")
    return {"status": "ok"}

# Usarlo
enviar_email_bienvenida.delay(123)
```

**Eso es todo**. No necesitas tocar nada mÃ¡s.

---

## SIGUIENTE PASO: AGENTES

Ya sabes quÃ© necesitas para hacer automatizaciones con cÃ³digo. Ahora falta entender **AGENTES con LangChain**.

Â¿Quieres que te explique quÃ© necesitas instalar y configurar para usar agentes con LLMs? ðŸ¤–
